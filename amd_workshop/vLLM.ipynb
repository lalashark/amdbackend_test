{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "44d39fcb",
   "metadata": {},
   "source": [
    "### 1. 安裝必要的套件\n",
    "\n",
    "此儲存格使用 `%pip` 指令來安裝與 vLLM 伺服器互動所需的 Python 函式庫：\n",
    "- `requests`: 用於發送 HTTP 請求以檢查伺服器狀態和模型。\n",
    "- `openai`: 用於與符合 OpenAI API 標準的端點進行互動，例如 vLLM。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "de1cf4bc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting requests\n",
      "  Using cached requests-2.32.5-py3-none-any.whl.metadata (4.9 kB)\n",
      "Collecting openai\n",
      "  Downloading openai-2.8.0-py3-none-any.whl.metadata (29 kB)\n",
      "Collecting charset_normalizer<4,>=2 (from requests)\n",
      "  Using cached charset_normalizer-3.4.4-cp312-cp312-manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_28_x86_64.whl.metadata (37 kB)\n",
      "Collecting idna<4,>=2.5 (from requests)\n",
      "  Using cached idna-3.11-py3-none-any.whl.metadata (8.4 kB)\n",
      "Collecting urllib3<3,>=1.21.1 (from requests)\n",
      "  Using cached urllib3-2.5.0-py3-none-any.whl.metadata (6.5 kB)\n",
      "Collecting certifi>=2017.4.17 (from requests)\n",
      "  Downloading certifi-2025.11.12-py3-none-any.whl.metadata (2.5 kB)\n",
      "Collecting anyio<5,>=3.5.0 (from openai)\n",
      "  Using cached anyio-4.11.0-py3-none-any.whl.metadata (4.1 kB)\n",
      "Collecting distro<2,>=1.7.0 (from openai)\n",
      "  Using cached distro-1.9.0-py3-none-any.whl.metadata (6.8 kB)\n",
      "Collecting httpx<1,>=0.23.0 (from openai)\n",
      "  Using cached httpx-0.28.1-py3-none-any.whl.metadata (7.1 kB)\n",
      "Collecting jiter<1,>=0.10.0 (from openai)\n",
      "  Downloading jiter-0.12.0-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (5.2 kB)\n",
      "Collecting pydantic<3,>=1.9.0 (from openai)\n",
      "  Downloading pydantic-2.12.4-py3-none-any.whl.metadata (89 kB)\n",
      "Collecting sniffio (from openai)\n",
      "  Using cached sniffio-1.3.1-py3-none-any.whl.metadata (3.9 kB)\n",
      "Collecting tqdm>4 (from openai)\n",
      "  Using cached tqdm-4.67.1-py3-none-any.whl.metadata (57 kB)\n",
      "Collecting typing-extensions<5,>=4.11 (from openai)\n",
      "  Using cached typing_extensions-4.15.0-py3-none-any.whl.metadata (3.3 kB)\n",
      "Collecting httpcore==1.* (from httpx<1,>=0.23.0->openai)\n",
      "  Using cached httpcore-1.0.9-py3-none-any.whl.metadata (21 kB)\n",
      "Collecting h11>=0.16 (from httpcore==1.*->httpx<1,>=0.23.0->openai)\n",
      "  Using cached h11-0.16.0-py3-none-any.whl.metadata (8.3 kB)\n",
      "Collecting annotated-types>=0.6.0 (from pydantic<3,>=1.9.0->openai)\n",
      "  Using cached annotated_types-0.7.0-py3-none-any.whl.metadata (15 kB)\n",
      "Collecting pydantic-core==2.41.5 (from pydantic<3,>=1.9.0->openai)\n",
      "  Downloading pydantic_core-2.41.5-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (7.3 kB)\n",
      "Collecting typing-inspection>=0.4.2 (from pydantic<3,>=1.9.0->openai)\n",
      "  Using cached typing_inspection-0.4.2-py3-none-any.whl.metadata (2.6 kB)\n",
      "Using cached requests-2.32.5-py3-none-any.whl (64 kB)\n",
      "Using cached charset_normalizer-3.4.4-cp312-cp312-manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_28_x86_64.whl (153 kB)\n",
      "Using cached idna-3.11-py3-none-any.whl (71 kB)\n",
      "Using cached urllib3-2.5.0-py3-none-any.whl (129 kB)\n",
      "Downloading openai-2.8.0-py3-none-any.whl (1.0 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.0/1.0 MB\u001b[0m \u001b[31m7.0 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0m\n",
      "\u001b[?25hUsing cached anyio-4.11.0-py3-none-any.whl (109 kB)\n",
      "Using cached distro-1.9.0-py3-none-any.whl (20 kB)\n",
      "Using cached httpx-0.28.1-py3-none-any.whl (73 kB)\n",
      "Using cached httpcore-1.0.9-py3-none-any.whl (78 kB)\n",
      "Downloading jiter-0.12.0-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (361 kB)\n",
      "Downloading pydantic-2.12.4-py3-none-any.whl (463 kB)\n",
      "Downloading pydantic_core-2.41.5-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.1 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.1/2.1 MB\u001b[0m \u001b[31m29.6 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0m\n",
      "\u001b[?25hUsing cached typing_extensions-4.15.0-py3-none-any.whl (44 kB)\n",
      "Using cached annotated_types-0.7.0-py3-none-any.whl (13 kB)\n",
      "Downloading certifi-2025.11.12-py3-none-any.whl (159 kB)\n",
      "Using cached h11-0.16.0-py3-none-any.whl (37 kB)\n",
      "Using cached sniffio-1.3.1-py3-none-any.whl (10 kB)\n",
      "Using cached tqdm-4.67.1-py3-none-any.whl (78 kB)\n",
      "Using cached typing_inspection-0.4.2-py3-none-any.whl (14 kB)\n",
      "Installing collected packages: urllib3, typing-extensions, tqdm, sniffio, jiter, idna, h11, distro, charset_normalizer, certifi, annotated-types, typing-inspection, requests, pydantic-core, httpcore, anyio, pydantic, httpx, openai\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m19/19\u001b[0m [openai]18/19\u001b[0m [openai]c]\n",
      "\u001b[1A\u001b[2KSuccessfully installed annotated-types-0.7.0 anyio-4.11.0 certifi-2025.11.12 charset_normalizer-3.4.4 distro-1.9.0 h11-0.16.0 httpcore-1.0.9 httpx-0.28.1 idna-3.11 jiter-0.12.0 openai-2.8.0 pydantic-2.12.4 pydantic-core-2.41.5 requests-2.32.5 sniffio-1.3.1 tqdm-4.67.1 typing-extensions-4.15.0 typing-inspection-0.4.2 urllib3-2.5.0\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install requests openai"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9d2ad58",
   "metadata": {},
   "source": [
    "### 2. 檢查伺服器狀態並初始化客戶端\n",
    "\n",
    "此儲存格執行以下操作：\n",
    "1.  **定義伺服器端點**：設定 vLLM 伺服器的基本 URL。\n",
    "2.  **檢查可用模型**：向 `/models` 端點發送 GET 請求，以擷取伺服器上可用的模型列表。\n",
    "3.  **設定模型名稱**：從回應中提取模型名稱以供後續請求使用。如果伺服器無法連線或沒有模型可用，則會使用預設名稱。\n",
    "4.  **初始化 OpenAI 客戶端**：建立 `OpenAI` 客戶端的實例，並將其設定為指向 vLLM 伺服器的 `base_url`。`api_key` 設定為虛擬金鑰，因為此本地伺服器不需要身份驗證。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0cf3f937",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Available models: {'object': 'list', 'data': [{'id': 'openai/gpt-oss-120b', 'object': 'model', 'created': 1763086911, 'owned_by': 'vllm', 'root': 'openai/gpt-oss-120b', 'parent': None, 'max_model_len': 4096, 'permission': [{'id': 'modelperm-9a057c69181d440fa29659c7b4bee6ae', 'object': 'model_permission', 'created': 1763086911, 'allow_create_engine': False, 'allow_sampling': True, 'allow_logprobs': True, 'allow_search_indices': False, 'allow_view': True, 'allow_fine_tuning': False, 'organization': '*', 'group': None, 'is_blocking': False}]}]}\n",
      "Using model: openai/gpt-oss-120b\n"
     ]
    }
   ],
   "source": [
    "# 先檢查伺服器狀態\n",
    "import requests\n",
    "\n",
    "# 檢查可用模型\n",
    "vllm_gpt_oss_120b_1=\"http://210.61.209.139:45014/v1/\"\n",
    "vllm_gpt_oss_120b_2=\"http://210.61.209.139:45005/v1/\"\n",
    "\n",
    "base_url = vllm_gpt_oss_120b_1\n",
    "try:\n",
    "    response = requests.get(base_url+\"models\")\n",
    "    models = response.json()\n",
    "    print(\"Available models:\", models)\n",
    "    \n",
    "    # 取得實際的模型名稱\n",
    "    if models.get(\"data\"):\n",
    "        model_name = models[\"data\"][0][\"id\"]\n",
    "        print(f\"Using model: {model_name}\")\n",
    "    else:\n",
    "        print(\"No models available!\")\n",
    "        model_name = \"gpt-oss-120b\"  # 預設值\n",
    "except Exception as e:\n",
    "    print(f\"Error connecting to vLLM server: {e}\")\n",
    "    model_name = \"gpt-oss-120b\"\n",
    "\n",
    "# 初始化 OpenAI 客戶端\n",
    "from openai import OpenAI\n",
    "\n",
    "client = OpenAI(\n",
    "    base_url=base_url,\n",
    "    api_key=\"dummy-key\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e240be6d",
   "metadata": {},
   "source": [
    "### 3. 文字生成測試\n",
    "\n",
    "此儲存格使用 `client.completions.create` 方法測試基本文字生成功能。\n",
    "\n",
    "它會：\n",
    "1.  發送一個簡單的提示 (`\"Once upon a time in a magical forest,\"`)。\n",
    "2.  列印生成的文字。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "578c1a30",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prompt: Once upon a time in a magical forest,\n",
      "Generated text:  Tim,\" the rabbit **here** is a h**im all set in a beautiful **. Sunny\n",
      "\n",
      "Here is your revised storyline had that being\n",
      "Te\n",
      "\n",
      "It seems like you're crafting a story involving a rabbit character named Tim who is set in a magical forest, possibly focusing on themes of simplicity and beauty. However, the provided text is a bit fragmented and unclear.\n",
      "\n",
      "If you could provide a more cohesive version or specify particular aspects you'd like to develop or enhance, I could assist further in refining the\n"
     ]
    }
   ],
   "source": [
    "# 文字生成測試 \n",
    "\n",
    "message=\"Once upon a time in a magical forest,\"\n",
    "\n",
    "try:\n",
    "    \n",
    "    response = client.completions.create(\n",
    "        model=model_name,\n",
    "        prompt=message,\n",
    "        max_tokens=100,\n",
    "        temperature=0.8\n",
    "    )\n",
    "    \n",
    "\n",
    "    \n",
    "    generated_text = response.choices[0].text\n",
    "    print(\"Prompt:\", message)\n",
    "    print(\"Generated text:\", generated_text)\n",
    "    \n",
    "        \n",
    "except Exception as e:\n",
    "    print(f\"Error: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "780ffbe5",
   "metadata": {},
   "source": [
    "### 4. 聊天補全測試\n",
    "\n",
    "此儲存格使用 `client.chat.completions.create` 方法測試聊天功能。此方法更適合對話式或指令式的互動。\n",
    "\n",
    "它會：\n",
    "1.  發送包含系統訊息（設定助理的行為）和使用者訊息（問題）的對話歷史記錄。\n",
    "2.  列印模型的聊天回應。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f03ff5f9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chat response: analysisThe user asks: \"Explain machine learning in one paragraph.\" Straightforward. Provide concise paragraph. No disallowed content. Provide answer.assistantfinalMachine learning is a branch of artificial intelligence that enables computers to automatically improve their performance on a specific task by learning from data rather than being explicitly programmed. It involves training algorithms—such as decision trees, neural networks, or support‑vector machines—on large datasets so they can recognize patterns, make predictions, or uncover hidden structures. As the model processes more examples, it adjusts its internal parameters to reduce errors, allowing it to generalize to new, unseen inputs. This data‑driven approach powers applications ranging from image and speech recognition to recommendation systems and autonomous vehicles.\n"
     ]
    }
   ],
   "source": [
    "# Chat completion 測試\n",
    "\n",
    "try:\n",
    "   \n",
    "    chat_response = client.chat.completions.create(\n",
    "        model=model_name,\n",
    "        messages=[\n",
    "            {\"role\": \"system\", \"content\": \"You are a helpful assistant.\"},\n",
    "            {\"role\": \"user\", \"content\": \"Explain machine learning in one paragraph.\"}\n",
    "        ],\n",
    "        temperature=0.7\n",
    "    )\n",
    "    \n",
    "    response_content = chat_response.choices[0].message.content\n",
    "    print(\"Chat response:\", response_content)\n",
    "    \n",
    "        \n",
    "except Exception as e:\n",
    "    print(f\"Chat error: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e958ef3",
   "metadata": {},
   "source": [
    "### 5. 推理能力測試 - 複雜邏輯謎題\n",
    "\n",
    "此儲存格旨在透過給予一個需要逐步推理的複雜邏輯謎題來評估模型的推理能力。\n",
    "\n",
    "它會：\n",
    "1.  使用系統提示，指示模型「逐步思考」。\n",
    "2.  提供一個包含多個線索的邏輯謎題。\n",
    "3.  將 `temperature` 設定為較低的值 (`0.1`)，以鼓勵更具確定性和邏輯性的一致回應。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a466a2a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reasoning Response: analysisWe need to solve puzzle. Use deduction. Let's define persons: Alice, Bob, Carol. Pets: cat, dog, bird. Houses: red, blue, green.\n",
      "\n",
      "Clues:\n",
      "\n",
      "1. Alice != red house.\n",
      "2. Cat -> blue house (person with cat lives in blue house). So blue house occupant has cat.\n",
      "3. Bob != bird.\n",
      "4. Carol != green house.\n",
      "5. Red house occupant has dog.\n",
      "\n",
      "We need assign each person a unique house and pet.\n",
      "\n",
      "Let's reason.\n",
      "\n",
      "Let’s denote house assignments.\n",
      "\n",
      "From 2, blue house occupant has cat. So pet cat is with blue house.\n",
      "\n",
      "From 5, red house occupant has dog. So pet dog is with red house.\n",
      "\n",
      "Thus bird is with green house (since remaining house). So green house occupant has bird.\n",
      "\n",
      "Now assign houses to persons with constraints.\n",
      "\n",
      "Alice not red. Carol not green. So possibilities:\n",
      "\n",
      "- Alice can be blue or green.\n",
      "- Carol can be red or blue.\n",
      "- Bob can be any (red, blue, green) but must satisfy other constraints.\n",
      "\n",
      "Also Bob doesn't have bird, so Bob cannot be in green house (since green house has bird). So Bob cannot be green house.\n",
      "\n",
      "Thus Bob must be red or blue.\n",
      "\n",
      "Now consider house-pet mapping:\n",
      "\n",
      "- Blue house -> cat.\n",
      "- Red house -> dog.\n",
      "- Green house -> bird.\n",
      "\n",
      "Thus if a person lives in a house, they have the corresponding pet.\n",
      "\n",
      "Now assign houses to persons respecting constraints.\n",
      "\n",
      "Let's try possibilities.\n",
      "\n",
      "Case 1: Alice in blue house. Then Alice has cat. Alice not red satisfied. Carol cannot be green, so Carol must be red (since remaining houses: red, green). But Carol cannot be green, so yes Carol red. Then Carol has dog. Bob gets remaining house green. But Bob cannot have bird (green house has bird). Contradiction. So Alice cannot be blue.\n",
      "\n",
      "Thus Alice must be green house. Then Alice has bird. Check: Alice not red satisfied. Good.\n",
      "\n",
      "Now remaining houses: red and blue for Bob and Carol.\n",
      "\n",
      "Carol cannot be green (already taken), so she can be red or blue. Bob cannot be green (already taken) and also cannot have bird, but bird is with Alice, fine. So Bob can be red or blue.\n",
      "\n",
      "Now apply constraints: Bob doesn't have bird (already satisfied). No other constraints.\n",
      "\n",
      "Now we need to assign red house (dog) and blue house (cat) to Bob and\n"
     ]
    }
   ],
   "source": [
    "# Reasoning Effort 測試 - 複雜推理任務\n",
    "\n",
    "try:\n",
    "    \n",
    "    reasoning_response = client.chat.completions.create(\n",
    "        model=model_name,\n",
    "        messages=[\n",
    "            {\"role\": \"system\", \"content\": \"You are an expert problem solver. Think step by step and show your reasoning process.\"},\n",
    "            {\"role\": \"user\", \"content\": \"\"\"\n",
    "            Solve this logic puzzle step by step:\n",
    "            \n",
    "            Three friends - Alice, Bob, and Carol - each have a different pet (cat, dog, bird) and live in different colored houses (red, blue, green).\n",
    "            \n",
    "            Clues:\n",
    "            1. Alice doesn't live in the red house\n",
    "            2. The person with the cat lives in the blue house\n",
    "            3. Bob doesn't have a bird\n",
    "            4. Carol doesn't live in the green house\n",
    "            5. The person in the red house has a dog\n",
    "            \n",
    "            Who has which pet and lives in which house?\n",
    "            \"\"\"}\n",
    "        ],\n",
    "        temperature=0.1,  # 低溫度確保邏輯一致性\n",
    "        max_tokens=500\n",
    "    )\n",
    "    \n",
    "    \n",
    "    reasoning_content = reasoning_response.choices[0].message.content\n",
    "    print(\"Reasoning Response:\", reasoning_content)\n",
    "    \n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"Reasoning error: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "823f6bd2",
   "metadata": {},
   "source": [
    "### 6. 推理能力測試 - 數學問題\n",
    "\n",
    "此儲存格透過一個需要基本數學計算的簡單問題，繼續測試模型的推理能力。\n",
    "\n",
    "它會：\n",
    "1.  要求模型解決一個關於速度和距離的數學應用題，並「展示其解題過程」。\n",
    "2.  此測試中的 `reasoning_effort=\"high\"` 是一個範例參數，用於展示如何向 API 發出需要更強推理能力的信號（請注意，此參數可能並非在所有 vLLM 設定中都為標準功能）。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "befce0af",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Prompt: A train travels 120 km in 2 hours. If it maintains the same speed, how far will it travel in 5 hours? Please show your work.\n",
      "\n",
      "Math Reasoning Response: analysisWe need to solve: speed = distance/time = 120 km / 2 h = 60 km/h. In 5 hours, distance = speed * time = 60 * 5 = 300 km. Show work.assistantfinal**Step 1: Find the train’s speed**\n",
      "\n",
      "The speed \\(v\\) is the distance traveled divided by the time taken.\n",
      "\n",
      "\\[\n",
      "v = \\frac{\\text{distance}}{\\text{time}} = \\frac{120\\ \\text{km}}{2\\ \\text{h}} = 60\\ \\text{km/h}\n",
      "\\]\n",
      "\n",
      "So the train moves at **60 kilometers per hour**.\n",
      "\n",
      "---\n",
      "\n",
      "**Step 2: Use the speed to find the distance for 5 hours**\n",
      "\n",
      "If the speed stays the same, distance traveled is:\n",
      "\n",
      "\\[\n",
      "\\text{distance} = \\text{speed} \\times \\text{time}\n",
      "\\]\n",
      "\n",
      "Plug in the values:\n",
      "\n",
      "\\[\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 簡化推理測試 - 數學問題\n",
    "\n",
    "try:\n",
    "\n",
    "    system_prompt=\"You are a helpful math tutor. Solve problems step by step.\"\n",
    "    user_prompt=\"A train travels 120 km in 2 hours. If it maintains the same speed, how far will it travel in 5 hours? Please show your work.\"\n",
    "    \n",
    "    math_response = client.chat.completions.create(\n",
    "        model=model_name,\n",
    "        messages=[\n",
    "            {\"role\": \"system\", \"content\": system_prompt},\n",
    "            {\"role\": \"user\", \"content\": user_prompt}\n",
    "        ],\n",
    "        temperature=0.3,\n",
    "        max_tokens=200,\n",
    "        reasoning_effort=\"high\"\n",
    "    )\n",
    "\n",
    "    \n",
    "    math_content = math_response.choices[0].message.content\n",
    "    print(\"\\n\")\n",
    "    print(\"Prompt:\", user_prompt)\n",
    "    print(\"\\nMath Reasoning Response:\", math_content)\n",
    "    \n",
    "        \n",
    "except Exception as e:\n",
    "    print(f\"Math reasoning error: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "527e01d3",
   "metadata": {},
   "source": [
    "### 7. 模型診斷測試\n",
    "\n",
    "此最後一個儲存格執行快速診斷，以檢查模型輸出的基本品質和健全性。\n",
    "\n",
    "它會：\n",
    "1.  迭代一組簡單、多樣的提示（一個數學問題、一個解釋性問題和一個列表請求）。\n",
    "2.  對於每個提示，它會擷取回應並測量延遲。\n",
    "3.  執行基本的品質檢查：\n",
    "    - 確保回應不為空。\n",
    "    - 檢查字元多樣性，以標記潛在的重複性問題（例如，模型輸出重複的字元）。\n",
    "4.  根據檢查結果列印成功或警告訊息。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c86be754",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Test 1: What is 2+2? ---\n",
      "Response: analysisUser asks a simple math question: \"What is 2+2?\" Answer: 4. Probably just answer.assistantfinal2 + 2 = 4.\n",
      "✅ Output looks normal\n",
      "\n",
      "--- Test 2: Explain photosynthesis briefly. ---\n",
      "Response: analysisWe need to give brief explanation of photosynthesis. Probably a concise paragraph, mention light reactions, Calvin cycle, chlorophyll, CO2, water, O2, glucose. Also maybe equation. Should be clear.assistant\n",
      "✅ Output looks normal\n",
      "\n",
      "--- Test 3: List 3 colors. ---\n",
      "Response: analysisThe user asks: \"List 3 colors.\" Simple. Provide three colors. Probably just list them. Could be any three: red, blue, green. Provide as bullet list.assistantfinal- Red  \n",
      "-\n",
      "✅ Output looks normal\n"
     ]
    }
   ],
   "source": [
    "# 模型診斷測試 - 檢查輸出品質\n",
    "\n",
    "try:\n",
    "    # 測試不同的提示策略\n",
    "    prompts = [\n",
    "        \"What is 2+2?\",\n",
    "        \"Explain photosynthesis briefly.\",\n",
    "        \"List 3 colors.\"\n",
    "    ]\n",
    "    \n",
    "    for i, prompt in enumerate(prompts, 1):\n",
    "        print(f\"\\n--- Test {i}: {prompt} ---\")\n",
    "\n",
    "        \n",
    "        response = client.chat.completions.create(\n",
    "            model=model_name,\n",
    "            messages=[ \n",
    "                {\"role\": \"user\", \"content\": prompt}\n",
    "            ],\n",
    "            temperature=0.5,\n",
    "            max_tokens=50\n",
    "        )\n",
    "        \n",
    " \n",
    "        \n",
    "        content = response.choices[0].message.content\n",
    "        print(f\"Response: {content}\")\n",
    "        \n",
    "        # 檢查輸出品質\n",
    "        if content and len(content.strip()) > 0:\n",
    "            # 檢查是否有重複字符（如感嘆號問題）\n",
    "            if len(set(content)) < 5:  # 如果字符種類太少\n",
    "                print(\"⚠️ Warning: Low character diversity - possible repetition issue\")\n",
    "            else:\n",
    "                print(\"✅ Output looks normal\")\n",
    "        else:\n",
    "            print(\"❌ Empty or invalid response\")\n",
    "            \n",
    "except Exception as e:\n",
    "    print(f\"Diagnostic error: {e}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv (3.12.3)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
